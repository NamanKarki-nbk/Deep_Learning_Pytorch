{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467f29d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Dataset URL: https://www.kaggle.com/datasets/fedesoriano/cifar100\n",
      "Downloading cifar100.zip to ./cifar100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161M/161M [00:13<00:00, 12.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/datasets/fedesoriano/cifar100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d22e6994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d4a2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file =r\"/home/namankarki/Naman/3_months_of_data-science/Deep_Learning_Pytorch/cnn/cifar100/train\"\n",
    "test_data = r\"/home/namankarki/Naman/3_months_of_data-science/Deep_Learning_Pytorch/cnn/cifar100/test\"\n",
    "\n",
    "def load_data(filename):\n",
    "    with open (filename, \"rb\") as f:\n",
    "        data = pickle.load(f, encoding=\"bytes\")\n",
    "        images = data[b\"data\"]\n",
    "        labels = data[b\"fine_labels\"]\n",
    "        images = images.reshape(-1,3,32,32)\n",
    "        labels = np.array(labels)\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b228c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_data(train_file)\n",
    "test_images, test_labels = load_data(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b38d23f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n",
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc26aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # converts (3,32,32) to PIL Image\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),    # converts to float32 tensor [0,1]\n",
    "    transforms.Normalize(mean=[0.5071,0.4867,0.4408], std=[0.2675,0.2565,0.2761])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071,0.4867,0.4408], std=[0.2675,0.2565,0.2761])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8c0a5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transformation = None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transformation = transformation\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.images))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = np.transpose(image, (1,2,0))\n",
    "        if self.transformation:\n",
    "            image = self.transformation(image)\n",
    "            \n",
    "        label = torch.tensor(label, dtype = torch.long)\n",
    "        \n",
    "        return image , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0e9712d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CustomDataset(train_images,train_labels,train_transform)\n",
    "testing_dataset = CustomDataset(test_images, test_labels,test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e6ecc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset , batch_size = 64, shuffle = True)\n",
    "testing_dataloader = DataLoader(testing_dataset , batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc73f157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-0.0339, -0.0339, -0.0925,  ..., -0.1512, -0.2391, -0.6789],\n",
       "           [-0.0925, -0.0192, -0.0485,  ..., -0.3711, -0.1512, -0.0192],\n",
       "           [-0.3711, -0.0192,  0.0248,  ..., -0.5763, -0.5470, -0.2538],\n",
       "           ...,\n",
       "           [-1.3826, -1.4266, -1.4412,  ...,  0.2886,  0.1420,  0.0394],\n",
       "           [-1.3679, -1.4119, -1.4266,  ...,  0.2447,  0.0981,  0.0394],\n",
       "           [-1.3679, -1.4119, -1.4412,  ...,  0.2007,  0.0541, -0.0046]],\n",
       " \n",
       "          [[ 0.0289, -0.1240, -0.2310,  ..., -0.3992, -0.5215, -0.8273],\n",
       "           [ 0.1971,  0.2277,  0.0442,  ..., -0.2769, -0.3533, -0.3074],\n",
       "           [-0.0781,  0.3347,  0.3653,  ..., -0.1393, -0.2769, -0.2616],\n",
       "           ...,\n",
       "           [-1.3776, -1.4235, -1.4235,  ...,  0.9004,  0.7169,  0.6099],\n",
       "           [-1.3624, -1.4082, -1.4235,  ...,  0.8392,  0.6863,  0.6405],\n",
       "           [-1.3624, -1.3929, -1.4235,  ...,  0.7628,  0.6405,  0.5793]],\n",
       " \n",
       "          [[-0.5171, -0.8153, -1.0852,  ..., -0.6591, -0.7017, -0.8153],\n",
       "           [ 0.1363,  0.1647, -0.0341,  ..., -0.3182, -0.5455, -0.5739],\n",
       "           [-0.0341,  0.4062,  0.4346,  ...,  0.0653, -0.1762, -0.3750],\n",
       "           ...,\n",
       "           [-1.3267, -1.3409, -1.3267,  ...,  1.0879,  0.9033,  0.8039],\n",
       "           [-1.3267, -1.3267, -1.3267,  ...,  1.0453,  0.8891,  0.8465],\n",
       "           [-1.3551, -1.3551, -1.3267,  ...,  0.9743,  0.8607,  0.8039]]],\n",
       " \n",
       " \n",
       "         [[[-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
       "           [-0.9721, -0.9721, -0.9281,  ..., -1.8957, -1.8957, -1.8957],\n",
       "           ...,\n",
       "           [-1.3679, -1.2653, -1.4412,  ..., -1.8957, -1.8957, -1.8957],\n",
       "           [-1.4559, -1.3386, -1.5292,  ..., -1.8957, -1.8957, -1.8957],\n",
       "           [-1.5145, -1.3093, -1.2800,  ..., -1.8957, -1.8957, -1.8957]],\n",
       " \n",
       "          [[-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
       "           [-0.2921, -0.2463, -0.1851,  ..., -1.8975, -1.8975, -1.8975],\n",
       "           ...,\n",
       "           [-1.4388, -1.3471, -1.5458,  ..., -1.8975, -1.8975, -1.8975],\n",
       "           [-1.5000, -1.3776, -1.5611,  ..., -1.8975, -1.8975, -1.8975],\n",
       "           [-1.5458, -1.3165, -1.2706,  ..., -1.8975, -1.8975, -1.8975]],\n",
       " \n",
       "          [[-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
       "           [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
       "           [ 0.6192,  0.6476,  0.7186,  ..., -1.5965, -1.5965, -1.5965],\n",
       "           ...,\n",
       "           [-1.2983, -1.1704, -1.2983,  ..., -1.5965, -1.5965, -1.5965],\n",
       "           [-1.3125, -1.1846, -1.3267,  ..., -1.5965, -1.5965, -1.5965],\n",
       "           [-1.3409, -1.1278, -1.0710,  ..., -1.5965, -1.5965, -1.5965]]],\n",
       " \n",
       " \n",
       "         [[[-1.8957, -1.8957,  1.3149,  ...,  1.4615,  1.4615,  1.4615],\n",
       "           [-1.8957, -1.8957,  1.3002,  ...,  1.4468,  1.4468,  1.4468],\n",
       "           [-1.8957, -1.8957,  1.2855,  ...,  1.4468,  1.4468,  1.4468],\n",
       "           ...,\n",
       "           [-1.8957, -1.8957,  0.6991,  ...,  1.6667,  1.6960,  1.7107],\n",
       "           [-1.8957, -1.8957, -0.1658,  ...,  1.6814,  1.6667,  1.6814],\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957]],\n",
       " \n",
       "          [[-1.8975, -1.8975,  1.6954,  ...,  1.8330,  1.8330,  1.8330],\n",
       "           [-1.8975, -1.8975,  1.6954,  ...,  1.8177,  1.8177,  1.8177],\n",
       "           [-1.8975, -1.8975,  1.6648,  ...,  1.7871,  1.8024,  1.8024],\n",
       "           ...,\n",
       "           [-1.8975, -1.8975,  0.6405,  ...,  1.5119,  1.5272,  1.5578],\n",
       "           [-1.8975, -1.8975, -0.2921,  ...,  1.5425,  1.5119,  1.5425],\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975]],\n",
       " \n",
       "          [[-1.5965, -1.5965,  1.8407,  ...,  1.9401,  1.9401,  1.9401],\n",
       "           [-1.5965, -1.5965,  1.8407,  ...,  1.9259,  1.9259,  1.9259],\n",
       "           [-1.5965, -1.5965,  1.7981,  ...,  1.8691,  1.8691,  1.8833],\n",
       "           ...,\n",
       "           [-1.5965, -1.5965,  0.1931,  ...,  0.9175,  0.9459,  0.9601],\n",
       "           [-1.5965, -1.5965, -0.3608,  ...,  0.9601,  0.9459,  0.9601],\n",
       "           [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.8957, -1.8957, -1.8957,  ..., -0.6056, -0.6496, -0.6936],\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -0.6203, -0.6643, -0.7229],\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -0.6349, -0.6789, -0.7229],\n",
       "           ...,\n",
       "           [-1.8957, -1.8957, -1.8957,  ...,  1.3149,  1.2562,  1.2855],\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957]],\n",
       " \n",
       "          [[-1.8975, -1.8975, -1.8975,  ..., -0.3380, -0.3380, -0.3686],\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -0.3533, -0.3380, -0.3686],\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -0.3686, -0.3380, -0.3686],\n",
       "           ...,\n",
       "           [-1.8975, -1.8975, -1.8975,  ...,  1.4508,  1.3896,  1.4355],\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975]],\n",
       " \n",
       "          [[-1.5965, -1.5965, -1.5965,  ..., -0.7585, -0.8295, -0.9006],\n",
       "           [-1.5965, -1.5965, -1.5965,  ..., -0.7869, -0.8437, -0.9148],\n",
       "           [-1.5965, -1.5965, -1.5965,  ..., -0.7869, -0.8437, -0.9148],\n",
       "           ...,\n",
       "           [-1.5965, -1.5965, -1.5965,  ...,  1.5282,  1.4714,  1.4430],\n",
       "           [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
       "           [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965]]],\n",
       " \n",
       " \n",
       "         [[[-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957],\n",
       "           [ 1.2709,  1.2709,  1.1683,  ..., -1.8957, -1.8957, -1.8957],\n",
       "           ...,\n",
       "           [ 0.2593, -0.7229, -0.3857,  ..., -1.8957, -1.8957, -1.8957],\n",
       "           [-0.1951, -0.9575, -0.6496,  ..., -1.8957, -1.8957, -1.8957],\n",
       "           [-0.0485, -0.3271, -0.5470,  ..., -1.8957, -1.8957, -1.8957]],\n",
       " \n",
       "          [[-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975],\n",
       "           [ 1.6801,  1.7413,  1.6190,  ..., -1.8975, -1.8975, -1.8975],\n",
       "           ...,\n",
       "           [ 0.6405, -0.5062, -0.0322,  ..., -1.8975, -1.8975, -1.8975],\n",
       "           [ 0.2583, -0.7661, -0.4145,  ..., -1.8975, -1.8975, -1.8975],\n",
       "           [ 0.4417,  0.0748, -0.1240,  ..., -1.8975, -1.8975, -1.8975]],\n",
       " \n",
       "          [[-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
       "           [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965],\n",
       "           [ 1.6703,  1.7981,  1.6419,  ..., -1.5965, -1.5965, -1.5965],\n",
       "           ...,\n",
       "           [ 0.0085, -0.9290, -1.0852,  ..., -1.5965, -1.5965, -1.5965],\n",
       "           [-0.4034, -0.9290, -0.8864,  ..., -1.5965, -1.5965, -1.5965],\n",
       "           [-0.4034, -0.7443, -0.9432,  ..., -1.5965, -1.5965, -1.5965]]],\n",
       " \n",
       " \n",
       "         [[[-1.8957, -1.8957, -1.8957,  ..., -0.1512,  0.1567,  0.3913],\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -0.5030, -0.2391, -0.0485],\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -0.6203, -0.5763, -0.5323],\n",
       "           ...,\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -0.6349, -0.7229, -0.7229],\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -0.6203, -0.7376, -0.7815],\n",
       "           [-1.8957, -1.8957, -1.8957,  ..., -1.8957, -1.8957, -1.8957]],\n",
       " \n",
       "          [[-1.8975, -1.8975, -1.8975,  ...,  0.2124,  0.4417,  0.6252],\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -0.0475,  0.1665,  0.3041],\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -0.2004, -0.1393, -0.0628],\n",
       "           ...,\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -0.5826, -0.6591, -0.6285],\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -0.5673, -0.6744, -0.6897],\n",
       "           [-1.8975, -1.8975, -1.8975,  ..., -1.8975, -1.8975, -1.8975]],\n",
       " \n",
       "          [[-1.5965, -1.5965, -1.5965,  ...,  0.4062,  0.6618,  0.8465],\n",
       "           [-1.5965, -1.5965, -1.5965,  ...,  0.2073,  0.4346,  0.5624],\n",
       "           [-1.5965, -1.5965, -1.5965,  ...,  0.0937,  0.2073,  0.2499],\n",
       "           ...,\n",
       "           [-1.5965, -1.5965, -1.5965,  ..., -0.2472, -0.2898, -0.2756],\n",
       "           [-1.5965, -1.5965, -1.5965,  ..., -0.2188, -0.3040, -0.3324],\n",
       "           [-1.5965, -1.5965, -1.5965,  ..., -1.5965, -1.5965, -1.5965]]]]),\n",
       " tensor([44, 76, 31, 96, 38, 86, 33, 52,  0, 58, 60, 72, 98, 16, 52, 73, 91, 76,\n",
       "         84,  0, 88, 90, 60, 69, 98, 38, 65, 83, 50, 52, 79, 52, 46, 78, 86, 70,\n",
       "         94, 32, 70, 55, 76, 89,  5, 19, 53, 95, 83, 71, 57, 93, 78,  7, 24, 59,\n",
       "          9, 13, 62, 26, 48,  2,  9, 14, 66, 33])]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(training_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "863c78e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "data = iter(training_dataloader)\n",
    "img, lbl = next(data)\n",
    "print(img.shape)\n",
    "print(lbl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3f20c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "21b7e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = resnet.fc.in_features\n",
    "resnet_fc = nn.Linear(num_ftrs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cafddf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1d0241dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(params = resnet.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7d32d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_accs = [], []\n",
    "val_losses, val_accs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fc3b6a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 3.8681, Train Acc: 0.1509 | Val Loss: 3.1151, Val Acc: 0.2808\n",
      "Epoch [2/10] Train Loss: 2.9225, Train Acc: 0.2835 | Val Loss: 2.8688, Val Acc: 0.3448\n",
      "Epoch [3/10] Train Loss: 2.6346, Train Acc: 0.3355 | Val Loss: 2.2162, Val Acc: 0.4104\n",
      "Epoch [4/10] Train Loss: 2.3989, Train Acc: 0.3764 | Val Loss: 2.1591, Val Acc: 0.4246\n",
      "Epoch [5/10] Train Loss: 2.6172, Train Acc: 0.3378 | Val Loss: 2.2141, Val Acc: 0.4213\n",
      "Epoch [6/10] Train Loss: 2.1380, Train Acc: 0.4247 | Val Loss: 2.0518, Val Acc: 0.4563\n",
      "Epoch [7/10] Train Loss: 1.9848, Train Acc: 0.4597 | Val Loss: 1.9449, Val Acc: 0.4852\n",
      "Epoch [8/10] Train Loss: 1.8425, Train Acc: 0.4907 | Val Loss: 2.1876, Val Acc: 0.4356\n",
      "Epoch [9/10] Train Loss: 1.8566, Train Acc: 0.4910 | Val Loss: 1.9309, Val Acc: 0.4981\n",
      "Epoch [10/10] Train Loss: 1.7371, Train Acc: 0.5153 | Val Loss: 1.7932, Val Acc: 0.5121\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "train_losses, train_accs = [], []\n",
    "val_losses, val_accs = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    resnet.train()\n",
    "    for image, label in training_dataloader:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = resnet(image)\n",
    "        batch_loss = criterion(logits, label)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += batch_loss.item() * label.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        train_acc += (preds == label).sum().item()\n",
    "\n",
    "    avg_loss = train_loss / len(training_dataset)\n",
    "    avg_acc  = train_acc / len(training_dataset)\n",
    "\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accs.append(avg_acc)\n",
    "\n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "\n",
    "    resnet.eval()\n",
    "    with torch.no_grad():\n",
    "        for image, label in testing_dataloader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            logits = resnet(image)\n",
    "            batch_loss = criterion(logits, label)\n",
    "\n",
    "            val_loss += batch_loss.item() * label.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            val_acc += (preds == label).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(testing_dataset)\n",
    "    avg_val_acc  = val_acc / len(testing_dataset)\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accs.append(avg_val_acc)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "        f\"Train Loss: {avg_loss:.4f}, Train Acc: {avg_acc:.4f} | \"\n",
    "        f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44224541",
   "metadata": {},
   "source": [
    "Freezing layers can be done to imporve the result and learning rate decay can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a80bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
