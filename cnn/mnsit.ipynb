{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c67c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./mnist-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/datasets/hojjatk/mnist-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de57fea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import gzip\n",
    "\n",
    "device =  \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = f.read()\n",
    "    magic = int.from_bytes(data[0:4], 'big')\n",
    "    num_images = int.from_bytes(data[4:8], 'big')\n",
    "    rows = int.from_bytes(data[8:12], 'big')\n",
    "    cols = int.from_bytes(data[12:16], 'big')\n",
    "    images = np.frombuffer(data, dtype=np.uint8, offset=16)\n",
    "    images = images.reshape(num_images, 1, rows, cols).astype(np.float32) / 255.0\n",
    "    \n",
    "    # MNIST standardization\n",
    "    mean = 0.1307\n",
    "    std = 0.3081\n",
    "    images = (images - mean) / std\n",
    "    \n",
    "    return images\n",
    "\n",
    "def read_idx_labels(filename):\n",
    "    with open(filename, 'rb') as f:   # <-- normal binary open\n",
    "        data = f.read()\n",
    "        \n",
    "    magic = int.from_bytes(data[0:4], 'big')\n",
    "    num_labels = int.from_bytes(data[4:8], 'big')\n",
    "    \n",
    "    labels = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5974b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, images , labels):\n",
    "        self.images = torch.tensor(images, dtype = torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype = torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.images))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4619a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Ipath=r\"/home/namankarki/Naman/3_months_of_data-science/Deep_Learning_Pytorch/cnn/mnist-dataset/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte\"\n",
    "test_Lpath=r\"/home/namankarki/Naman/3_months_of_data-science/Deep_Learning_Pytorch/cnn/mnist-dataset/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte\"\n",
    "train_Ipath=r\"/home/namankarki/Naman/3_months_of_data-science/Deep_Learning_Pytorch/cnn/mnist-dataset/train-images-idx3-ubyte/train-images-idx3-ubyte\"\n",
    "train_Lpath=r=\"/home/namankarki/Naman/3_months_of_data-science/Deep_Learning_Pytorch/cnn/mnist-dataset/train-labels-idx1-ubyte/train-labels-idx1-ubyte\"\n",
    "\n",
    "\n",
    "\n",
    "test_images = read_idx_images(test_Ipath)\n",
    "test_labels = read_idx_labels(test_Lpath)\n",
    "train_images = read_idx_images(train_Ipath)\n",
    "train_labels = read_idx_labels(train_Lpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "532159a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataSet(train_images, train_labels)\n",
    "test_dataset = DataSet(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "783c47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "test_dataloader = DataLoader(train_dataset, batch_size = 100, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "566135bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "data=iter(train_dataloader)\n",
    "image,label = next(data)\n",
    "print(image.shape, label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "79cd98a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32,3), #yesle dine output vanya of shape(N,32,26,26)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3), #(N,64,24,24)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), #(N,64,12,12)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),#(N,64*12*12)\n",
    "            nn.Linear(64*12*12, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x=self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel().to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c5bbff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(params=model.parameters(), lr=0.001, betas=(0.9,0.999), eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c428973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: Train Loss = 0.1159, Train Acc = 0.9642, Val Loss = 0.2096, Val Acc = 5.9371\n",
      "Epoch 2/20: Train Loss = 0.0349, Train Acc = 0.9890, Val Loss = 0.1076, Val Acc = 5.9660\n",
      "Epoch 3/20: Train Loss = 0.0214, Train Acc = 0.9929, Val Loss = 0.1108, Val Acc = 5.9643\n",
      "Epoch 4/20: Train Loss = 0.0151, Train Acc = 0.9950, Val Loss = 0.0705, Val Acc = 5.9780\n",
      "Epoch 5/20: Train Loss = 0.0108, Train Acc = 0.9966, Val Loss = 0.0461, Val Acc = 5.9857\n",
      "Epoch 6/20: Train Loss = 0.0096, Train Acc = 0.9964, Val Loss = 0.0228, Val Acc = 5.9923\n",
      "Epoch 7/20: Train Loss = 0.0075, Train Acc = 0.9977, Val Loss = 0.0737, Val Acc = 5.9755\n",
      "Epoch 8/20: Train Loss = 0.0066, Train Acc = 0.9977, Val Loss = 0.0256, Val Acc = 5.9927\n",
      "Epoch 9/20: Train Loss = 0.0046, Train Acc = 0.9987, Val Loss = 0.0285, Val Acc = 5.9910\n",
      "Epoch 10/20: Train Loss = 0.0048, Train Acc = 0.9985, Val Loss = 0.0059, Val Acc = 5.9981\n",
      "Epoch 11/20: Train Loss = 0.0052, Train Acc = 0.9982, Val Loss = 0.0224, Val Acc = 5.9926\n",
      "Epoch 12/20: Train Loss = 0.0047, Train Acc = 0.9986, Val Loss = 0.0294, Val Acc = 5.9906\n",
      "Epoch 13/20: Train Loss = 0.0049, Train Acc = 0.9986, Val Loss = 0.0243, Val Acc = 5.9916\n",
      "Epoch 14/20: Train Loss = 0.0024, Train Acc = 0.9992, Val Loss = 0.0108, Val Acc = 5.9967\n",
      "Epoch 15/20: Train Loss = 0.0024, Train Acc = 0.9993, Val Loss = 0.0140, Val Acc = 5.9953\n",
      "Epoch 16/20: Train Loss = 0.0047, Train Acc = 0.9987, Val Loss = 0.0153, Val Acc = 5.9949\n",
      "Epoch 17/20: Train Loss = 0.0029, Train Acc = 0.9992, Val Loss = 0.0082, Val Acc = 5.9970\n",
      "Epoch 18/20: Train Loss = 0.0021, Train Acc = 0.9993, Val Loss = 0.0188, Val Acc = 5.9931\n",
      "Epoch 19/20: Train Loss = 0.0044, Train Acc = 0.9989, Val Loss = 0.0082, Val Acc = 5.9978\n",
      "Epoch 20/20: Train Loss = 0.0008, Train Acc = 0.9998, Val Loss = 0.0038, Val Acc = 5.9985\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_train_loss = 0\n",
    "    total_train_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item() * labels.size(0)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        total_train_acc += (preds == labels).sum().item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataset)\n",
    "    avg_train_acc = total_train_acc / len(train_dataset)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            val_loss += loss.item() * labels.size(0)\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            val_acc += (preds == labels).sum().item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(test_dataset)\n",
    "    avg_val_acc = val_acc / len(test_dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "          f\"Train Loss = {avg_train_loss:.4f}, Train Acc = {avg_train_acc:.4f}, \"\n",
    "          f\"Val Loss = {avg_val_loss:.4f}, Val Acc = {avg_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a004e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
