{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455a489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "import  torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd8ef1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./covertype-forest-cover-types\" (use force=True to force download)\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/zsinghrahulk/covertype-forest-cover-types\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ada74b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 1  Unnamed: 2  Elevation  Aspect  Slope  \\\n",
       "0        2596          51           3        258       0    510   \n",
       "1        2590          56           2        212      -6    390   \n",
       "2        2804         139           9        268      65   3180   \n",
       "3        2785         155          18        242     118   3090   \n",
       "4        2595          45           2        153      -1    391   \n",
       "\n",
       "   Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
       "0                               221                             232   \n",
       "1                               220                             235   \n",
       "2                               234                             238   \n",
       "3                               238                             238   \n",
       "4                               220                             234   \n",
       "\n",
       "   Horizontal_Distance_To_Roadways  Hillshade_9am  ...  Soil_Type32  \\\n",
       "0                              148           6279  ...            0   \n",
       "1                              151           6225  ...            0   \n",
       "2                              135           6121  ...            0   \n",
       "3                              122           6211  ...            0   \n",
       "4                              150           6172  ...            0   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0            0           5  \n",
       "1            0            0            0           5  \n",
       "2            0            0            0           2  \n",
       "3            0            0            0           2  \n",
       "4            0            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"/home/namankarki/Naman/3_months_of_data-science/Deep_Learning_Pytorch/gradient_decent/covertype-forest-cover-types/covertype.csv\"\n",
    "data_df = pd.read_csv(path)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b927674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Elevation', 'Aspect',\n",
       "       'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area', 'Soil_Type1',\n",
       "       'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6',\n",
       "       'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11',\n",
       "       'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15',\n",
       "       'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19',\n",
       "       'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23',\n",
       "       'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27',\n",
       "       'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31',\n",
       "       'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35',\n",
       "       'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39',\n",
       "       'Soil_Type40', 'Cover_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87134cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.drop(columns=(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64142013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0        258       0    510                               221   \n",
       "1        212      -6    390                               220   \n",
       "2        268      65   3180                               234   \n",
       "3        242     118   3090                               238   \n",
       "4        153      -1    391                               220   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                             232                              148   \n",
       "1                             235                              151   \n",
       "2                             238                              135   \n",
       "3                             238                              122   \n",
       "4                             234                              150   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0           6279               1              0   \n",
       "1           6225               1              0   \n",
       "2           6121               1              0   \n",
       "3           6211               1              0   \n",
       "4           6172               1              0   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                   0  ...            0            0   \n",
       "1                                   0  ...            0            0   \n",
       "2                                   0  ...            0            0   \n",
       "3                                   0  ...            0            0   \n",
       "4                                   0  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           5  \n",
       "1            0            0           5  \n",
       "2            0            0           2  \n",
       "3            0            0           2  \n",
       "4            0            0           5  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "331317fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Cover_Type']\n"
     ]
    }
   ],
   "source": [
    "columns=data_df.columns\n",
    "print(list(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee999699",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am']\n",
    "binary_cols = ['Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n",
    "label=['Cover_Type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97949951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Checking the NAN values\n",
      "Elevation                             0\n",
      "Aspect                                0\n",
      "Slope                                 0\n",
      "Horizontal_Distance_To_Hydrology      0\n",
      "Vertical_Distance_To_Hydrology        0\n",
      "Horizontal_Distance_To_Roadways       0\n",
      "Hillshade_9am                         0\n",
      "Hillshade_Noon                        0\n",
      "Hillshade_3pm                         0\n",
      "Horizontal_Distance_To_Fire_Points    0\n",
      "Wilderness_Area                       0\n",
      "Soil_Type1                            0\n",
      "Soil_Type2                            0\n",
      "Soil_Type3                            0\n",
      "Soil_Type4                            0\n",
      "Soil_Type5                            0\n",
      "Soil_Type6                            0\n",
      "Soil_Type7                            0\n",
      "Soil_Type8                            0\n",
      "Soil_Type9                            0\n",
      "Soil_Type10                           0\n",
      "Soil_Type11                           0\n",
      "Soil_Type12                           0\n",
      "Soil_Type13                           0\n",
      "Soil_Type14                           0\n",
      "Soil_Type15                           0\n",
      "Soil_Type16                           0\n",
      "Soil_Type17                           0\n",
      "Soil_Type18                           0\n",
      "Soil_Type19                           0\n",
      "Soil_Type20                           0\n",
      "Soil_Type21                           0\n",
      "Soil_Type22                           0\n",
      "Soil_Type23                           0\n",
      "Soil_Type24                           0\n",
      "Soil_Type25                           0\n",
      "Soil_Type26                           0\n",
      "Soil_Type27                           0\n",
      "Soil_Type28                           0\n",
      "Soil_Type29                           0\n",
      "Soil_Type30                           0\n",
      "Soil_Type31                           0\n",
      "Soil_Type32                           0\n",
      "Soil_Type33                           0\n",
      "Soil_Type34                           0\n",
      "Soil_Type35                           0\n",
      "Soil_Type36                           0\n",
      "Soil_Type37                           0\n",
      "Soil_Type38                           0\n",
      "Soil_Type39                           0\n",
      "Soil_Type40                           0\n",
      "Cover_Type                            0\n",
      "dtype: int64\n",
      "\n",
      " Checking the empty strings and unusual values\n",
      "Elevation                             0\n",
      "Aspect                                0\n",
      "Slope                                 0\n",
      "Horizontal_Distance_To_Hydrology      0\n",
      "Vertical_Distance_To_Hydrology        0\n",
      "Horizontal_Distance_To_Roadways       0\n",
      "Hillshade_9am                         0\n",
      "Hillshade_Noon                        0\n",
      "Hillshade_3pm                         0\n",
      "Horizontal_Distance_To_Fire_Points    0\n",
      "Wilderness_Area                       0\n",
      "Soil_Type1                            0\n",
      "Soil_Type2                            0\n",
      "Soil_Type3                            0\n",
      "Soil_Type4                            0\n",
      "Soil_Type5                            0\n",
      "Soil_Type6                            0\n",
      "Soil_Type7                            0\n",
      "Soil_Type8                            0\n",
      "Soil_Type9                            0\n",
      "Soil_Type10                           0\n",
      "Soil_Type11                           0\n",
      "Soil_Type12                           0\n",
      "Soil_Type13                           0\n",
      "Soil_Type14                           0\n",
      "Soil_Type15                           0\n",
      "Soil_Type16                           0\n",
      "Soil_Type17                           0\n",
      "Soil_Type18                           0\n",
      "Soil_Type19                           0\n",
      "Soil_Type20                           0\n",
      "Soil_Type21                           0\n",
      "Soil_Type22                           0\n",
      "Soil_Type23                           0\n",
      "Soil_Type24                           0\n",
      "Soil_Type25                           0\n",
      "Soil_Type26                           0\n",
      "Soil_Type27                           0\n",
      "Soil_Type28                           0\n",
      "Soil_Type29                           0\n",
      "Soil_Type30                           0\n",
      "Soil_Type31                           0\n",
      "Soil_Type32                           0\n",
      "Soil_Type33                           0\n",
      "Soil_Type34                           0\n",
      "Soil_Type35                           0\n",
      "Soil_Type36                           0\n",
      "Soil_Type37                           0\n",
      "Soil_Type38                           0\n",
      "Soil_Type39                           0\n",
      "Soil_Type40                           0\n",
      "Cover_Type                            0\n",
      "dtype: int64\n",
      "\n",
      " Checking the duplicates\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Checking the NAN values\")\n",
    "print(data_df.isnull().sum())\n",
    "\n",
    "print(\"\\n Checking the empty strings and unusual values\")\n",
    "print(data_df.isin([\"\", \"NA\", \"N/A\", \"NONE\", \"none\", \"na\", \"NULL\", \"null\", \"None\"]).sum())\n",
    "\n",
    "print(\"\\n Checking the duplicates\")\n",
    "print(data_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a097a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36361ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_df[numerical_cols] = scaler.fit_transform(data_df[numerical_cols])\n",
    "X = data_df.iloc[:,:-1]\n",
    "y=data_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91478756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 52)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b5d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42e46d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e7006ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((522910, 51), (29051, 51), (29051, 51))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b9adaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,X ,y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7504084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = dataset(X_train, y_train)\n",
    "validation_dataset = dataset(X_val, y_val)\n",
    "testing_dataset = dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "684d5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_dataset, batch_size=64, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "testing_dataloader = DataLoader(testing_dataset, batch_size= 64, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d70dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0700, -0.7620,  1.4884,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.1318,  0.6618,  0.3379,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1055,  0.0100,  0.7637,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-1.1265, -0.6590,  0.0576,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.4113, -0.7277, -0.4105,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 2.0069,  3.7839, -0.3092,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [7],\n",
      "        [6],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [1],\n",
      "        [2],\n",
      "        [7],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "for x , y in train_dataloader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86f3713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hidden_Neurons =108\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential (\n",
    "            nn.Linear(X.shape[1], Hidden_Neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(Hidden_Neurons, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU() \n",
    "        )\n",
    "        \n",
    "        self.classifier= nn.Sequential(\n",
    "            nn.Linear(16,7),\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = MyModel().to(device)\n",
    "#yo model ko output vanya batch size * 7 (7 ota calsses vako le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbeed6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 108]           5,616\n",
      "              ReLU-2                  [-1, 108]               0\n",
      "            Linear-3                   [-1, 64]           6,976\n",
      "              ReLU-4                   [-1, 64]               0\n",
      "            Linear-5                   [-1, 32]           2,080\n",
      "              ReLU-6                   [-1, 32]               0\n",
      "            Linear-7                   [-1, 16]             528\n",
      "              ReLU-8                   [-1, 16]               0\n",
      "            Linear-9                    [-1, 7]             119\n",
      "================================================================\n",
      "Total params: 15,319\n",
      "Trainable params: 15,319\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8d9c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion =nn.CrossEntropyLoss()\n",
    "optimizer =  SGD(model.parameters(), lr = 0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c167b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58959181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " Train Loss: 1.0561, Train Acc: 0.5251\n",
      " Val Loss:   0.8806, Val Acc:   0.6143\n",
      "Epoch 2/20\n",
      " Train Loss: 0.8040, Train Acc: 0.6518\n",
      " Val Loss:   0.7227, Val Acc:   0.6833\n",
      "Epoch 3/20\n",
      " Train Loss: 0.6872, Train Acc: 0.7036\n",
      " Val Loss:   0.6746, Val Acc:   0.7085\n",
      "Epoch 4/20\n",
      " Train Loss: 0.6468, Train Acc: 0.7204\n",
      " Val Loss:   0.6227, Val Acc:   0.7341\n",
      "Epoch 5/20\n",
      " Train Loss: 0.6202, Train Acc: 0.7309\n",
      " Val Loss:   0.6067, Val Acc:   0.7368\n",
      "Epoch 6/20\n",
      " Train Loss: 0.6014, Train Acc: 0.7382\n",
      " Val Loss:   0.5952, Val Acc:   0.7414\n",
      "Epoch 7/20\n",
      " Train Loss: 0.5838, Train Acc: 0.7453\n",
      " Val Loss:   0.5721, Val Acc:   0.7489\n",
      "Epoch 8/20\n",
      " Train Loss: 0.5669, Train Acc: 0.7529\n",
      " Val Loss:   0.5523, Val Acc:   0.7617\n",
      "Epoch 9/20\n",
      " Train Loss: 0.5515, Train Acc: 0.7605\n",
      " Val Loss:   0.5457, Val Acc:   0.7637\n",
      "Epoch 10/20\n",
      " Train Loss: 0.5373, Train Acc: 0.7661\n",
      " Val Loss:   0.5354, Val Acc:   0.7650\n",
      "Epoch 11/20\n",
      " Train Loss: 0.5254, Train Acc: 0.7709\n",
      " Val Loss:   0.5154, Val Acc:   0.7768\n",
      "Epoch 12/20\n",
      " Train Loss: 0.5145, Train Acc: 0.7763\n",
      " Val Loss:   0.5035, Val Acc:   0.7817\n",
      "Epoch 13/20\n",
      " Train Loss: 0.5041, Train Acc: 0.7804\n",
      " Val Loss:   0.5024, Val Acc:   0.7820\n",
      "Epoch 14/20\n",
      " Train Loss: 0.4950, Train Acc: 0.7843\n",
      " Val Loss:   0.5257, Val Acc:   0.7603\n",
      "Epoch 15/20\n",
      " Train Loss: 0.4866, Train Acc: 0.7882\n",
      " Val Loss:   0.4845, Val Acc:   0.7884\n",
      "Epoch 16/20\n",
      " Train Loss: 0.4780, Train Acc: 0.7923\n",
      " Val Loss:   0.4809, Val Acc:   0.7894\n",
      "Epoch 17/20\n",
      " Train Loss: 0.4708, Train Acc: 0.7952\n",
      " Val Loss:   0.4638, Val Acc:   0.7999\n",
      "Epoch 18/20\n",
      " Train Loss: 0.4643, Train Acc: 0.7983\n",
      " Val Loss:   0.4766, Val Acc:   0.7930\n",
      "Epoch 19/20\n",
      " Train Loss: 0.4585, Train Acc: 0.8016\n",
      " Val Loss:   0.4981, Val Acc:   0.7852\n",
      "Epoch 20/20\n",
      " Train Loss: 0.4528, Train Acc: 0.8035\n",
      " Val Loss:   0.5017, Val Acc:   0.7746\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = inputs.to(device)\n",
    "        y = (labels.to(device).squeeze(1)-1).long()\n",
    "        \n",
    "        logits = model(X)\n",
    "        batch_loss = criterion(logits, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += batch_loss.item() * y.size(0)\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        train_acc += (preds == y).sum().item()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(training_dataset)\n",
    "    avg_train_acc = train_acc / len(training_dataset)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_dataloader:\n",
    "            X = inputs.to(device)\n",
    "            y = (labels.to(device).squeeze(1)-1).long()\n",
    "            \n",
    "            logits = model(X)\n",
    "            batch_loss = criterion(logits, y)\n",
    "            \n",
    "            val_loss += batch_loss.item() * y.size(0)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            val_acc += (preds == y).sum().item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(validation_dataset)\n",
    "    avg_val_acc = val_acc / len(validation_dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\" Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}\")\n",
    "    print(f\" Val Loss:   {avg_val_loss:.4f}, Val Acc:   {avg_val_acc:.4f}\")\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2a89612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5085, Test Acc: 0.7740\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            X = inputs.to(device)\n",
    "            y = (labels.to(device).squeeze(1) - 1).long()\n",
    "            \n",
    "            logits = model(X)\n",
    "            batch_loss = criterion(logits, y)\n",
    "            \n",
    "            test_loss += batch_loss.item() * y.size(0)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            test_acc += (preds == y).sum().item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader.dataset)\n",
    "    avg_test_acc = test_acc / len(test_dataloader.dataset)\n",
    "    \n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Acc: {avg_test_acc:.4f}\")\n",
    "    \n",
    "    return avg_test_loss, avg_test_acc\n",
    "\n",
    "# Example usage after training:\n",
    "test_loss, test_acc = test_model(model, testing_dataloader, criterion, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260afaf",
   "metadata": {},
   "source": [
    "Adam Optimizer which also covers RMSPROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42c29d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hidden_Neurons = 108\n",
    "\n",
    "class MODEL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], Hidden_Neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(Hidden_Neurons, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16,7)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "mymodel = MODEL().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb3891bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 108]           5,616\n",
      "              ReLU-2                  [-1, 108]               0\n",
      "            Linear-3                   [-1, 64]           6,976\n",
      "              ReLU-4                   [-1, 64]               0\n",
      "            Linear-5                   [-1, 32]           2,080\n",
      "              ReLU-6                   [-1, 32]               0\n",
      "            Linear-7                   [-1, 16]             528\n",
      "              ReLU-8                   [-1, 16]               0\n",
      "            Linear-9                    [-1, 7]             119\n",
      "================================================================\n",
      "Total params: 15,319\n",
      "Trainable params: 15,319\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(mymodel, input_size= (X.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47311601",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(params= mymodel.parameters(), lr=0.001, betas=(0.9, 0.999), eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8ad1442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " Train Loss: 0.6685, Train Acc: 0.7000\n",
      " Val Loss:   0.5884, Val Acc:   0.7375\n",
      "Epoch 2/20\n",
      " Train Loss: 0.5594, Train Acc: 0.7506\n",
      " Val Loss:   0.5301, Val Acc:   0.7659\n",
      "Epoch 3/20\n",
      " Train Loss: 0.5147, Train Acc: 0.7705\n",
      " Val Loss:   0.5025, Val Acc:   0.7765\n",
      "Epoch 4/20\n",
      " Train Loss: 0.4866, Train Acc: 0.7836\n",
      " Val Loss:   0.4820, Val Acc:   0.7844\n",
      "Epoch 5/20\n",
      " Train Loss: 0.4641, Train Acc: 0.7940\n",
      " Val Loss:   0.4627, Val Acc:   0.7950\n",
      "Epoch 6/20\n",
      " Train Loss: 0.4464, Train Acc: 0.8025\n",
      " Val Loss:   0.4482, Val Acc:   0.8014\n",
      "Epoch 7/20\n",
      " Train Loss: 0.4308, Train Acc: 0.8099\n",
      " Val Loss:   0.4279, Val Acc:   0.8105\n",
      "Epoch 8/20\n",
      " Train Loss: 0.4185, Train Acc: 0.8158\n",
      " Val Loss:   0.4288, Val Acc:   0.8093\n",
      "Epoch 9/20\n",
      " Train Loss: 0.4081, Train Acc: 0.8215\n",
      " Val Loss:   0.4100, Val Acc:   0.8197\n",
      "Epoch 10/20\n",
      " Train Loss: 0.3986, Train Acc: 0.8262\n",
      " Val Loss:   0.4061, Val Acc:   0.8206\n",
      "Epoch 11/20\n",
      " Train Loss: 0.3905, Train Acc: 0.8302\n",
      " Val Loss:   0.3886, Val Acc:   0.8297\n",
      "Epoch 12/20\n",
      " Train Loss: 0.3835, Train Acc: 0.8344\n",
      " Val Loss:   0.3834, Val Acc:   0.8330\n",
      "Epoch 13/20\n",
      " Train Loss: 0.3779, Train Acc: 0.8364\n",
      " Val Loss:   0.3817, Val Acc:   0.8373\n",
      "Epoch 14/20\n",
      " Train Loss: 0.3720, Train Acc: 0.8395\n",
      " Val Loss:   0.3711, Val Acc:   0.8398\n",
      "Epoch 15/20\n",
      " Train Loss: 0.3673, Train Acc: 0.8414\n",
      " Val Loss:   0.3716, Val Acc:   0.8392\n",
      "Epoch 16/20\n",
      " Train Loss: 0.3623, Train Acc: 0.8441\n",
      " Val Loss:   0.3613, Val Acc:   0.8451\n",
      "Epoch 17/20\n",
      " Train Loss: 0.3582, Train Acc: 0.8463\n",
      " Val Loss:   0.3608, Val Acc:   0.8442\n",
      "Epoch 18/20\n",
      " Train Loss: 0.3535, Train Acc: 0.8484\n",
      " Val Loss:   0.3540, Val Acc:   0.8514\n",
      "Epoch 19/20\n",
      " Train Loss: 0.3503, Train Acc: 0.8496\n",
      " Val Loss:   0.3607, Val Acc:   0.8430\n",
      "Epoch 20/20\n",
      " Train Loss: 0.3470, Train Acc: 0.8517\n",
      " Val Loss:   0.3514, Val Acc:   0.8505\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "def training_validation(model,train_dataloader, validation_dataloader, criterion, optimizer):\n",
    "    for epoch in range(epochs):\n",
    "        total_train_loss = 0\n",
    "        total_train_acc = 0\n",
    "       \n",
    "        \n",
    "        for data, label in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            X = data.to(device)\n",
    "            y = (label.to(device).squeeze(1) - 1).long()\n",
    "            logits = model(X)\n",
    "            batch_loss = criterion(logits,y)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += batch_loss.item() * y.size(0)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            total_train_acc += (preds == y).sum().item()\n",
    "            \n",
    "        avg_train_loss = total_train_loss/len(training_dataset)\n",
    "        avg_train_acc = total_train_acc/len(training_dataset)\n",
    "    \n",
    "\n",
    "        # Validation\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validation_dataloader:\n",
    "                X = inputs.to(device)\n",
    "                y = (labels.to(device).squeeze(1)-1).long()\n",
    "                \n",
    "                logits = model(X)\n",
    "                batch_loss = criterion(logits, y)\n",
    "                \n",
    "                val_loss += batch_loss.item() * y.size(0)\n",
    "                _, preds = torch.max(logits, dim=1)\n",
    "                val_acc += (preds == y).sum().item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(validation_dataset)\n",
    "        avg_val_acc = val_acc / len(validation_dataset)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\" Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}\")\n",
    "        print(f\" Val Loss:   {avg_val_loss:.4f}, Val Acc:   {avg_val_acc:.4f}\")\n",
    "\n",
    "training_validation(mymodel, train_dataloader, validation_dataloader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1146c139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3508, Test Acc: 0.8506\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            X = inputs.to(device)\n",
    "            y = (labels.to(device).squeeze(1) - 1).long()\n",
    "            \n",
    "            logits = model(X)\n",
    "            batch_loss = criterion(logits, y)\n",
    "            \n",
    "            test_loss += batch_loss.item() * y.size(0)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            test_acc += (preds == y).sum().item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader.dataset)\n",
    "    avg_test_acc = test_acc / len(test_dataloader.dataset)\n",
    "    \n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Acc: {avg_test_acc:.4f}\")\n",
    "    \n",
    "    return avg_test_loss, avg_test_acc\n",
    "\n",
    "# Example usage after training:\n",
    "test_loss, test_acc = test_model(mymodel, testing_dataloader, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45385b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59, 51])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084419f7",
   "metadata": {},
   "source": [
    "ADAM + LEARNING RATE DECAY + WEIGHT DECAY + DROPOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0c053d",
   "metadata": {},
   "source": [
    "Other popular schedulers:\n",
    "\n",
    "ReduceLROnPlateau → reduces LR when validation loss stops improving\n",
    "\n",
    "ExponentialLR → continuous exponential decay\n",
    "\n",
    "CosineAnnealingLR → cyclic learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90bf0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hidden_Neurons = 108\n",
    "class ChadModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], Hidden_Neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(Hidden_Neurons, 64),\n",
    "            nn.ReLU(),\n",
    "             nn.Dropout(p=0.5),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "             nn.Dropout(p=0.5),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16,7)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "chadmodel = ChadModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc965abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chad_criterion = nn.CrossEntropyLoss()\n",
    "chad_optimizer = optim.Adam(params=model.parameters(), lr = 0.001, weight_decay= 1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(chad_optimizer, step_size= 10, gamma=0.5)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "959ee0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 1.9240, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.001000\n",
      "Epoch 2/20 | Train Loss: 1.9241, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.001000\n",
      "Epoch 3/20 | Train Loss: 1.9240, Train Acc: 0.3647 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.001000\n",
      "Epoch 4/20 | Train Loss: 1.9241, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.001000\n",
      "Epoch 5/20 | Train Loss: 1.9241, Train Acc: 0.3647 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.001000\n",
      "Epoch 6/20 | Train Loss: 1.9240, Train Acc: 0.3647 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.001000\n",
      "Epoch 7/20 | Train Loss: 1.9241, Train Acc: 0.3645 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.001000\n",
      "Epoch 8/20 | Train Loss: 1.9241, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.001000\n",
      "Epoch 9/20 | Train Loss: 1.9241, Train Acc: 0.3645 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.001000\n",
      "Epoch 10/20 | Train Loss: 1.9240, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.000500\n",
      "Epoch 11/20 | Train Loss: 1.9240, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.000500\n",
      "Epoch 12/20 | Train Loss: 1.9240, Train Acc: 0.3647 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.000500\n",
      "Epoch 13/20 | Train Loss: 1.9240, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.000500\n",
      "Epoch 14/20 | Train Loss: 1.9240, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.000500\n",
      "Epoch 15/20 | Train Loss: 1.9241, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.000500\n",
      "Epoch 16/20 | Train Loss: 1.9241, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.000500\n",
      "Epoch 17/20 | Train Loss: 1.9240, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.000500\n",
      "Epoch 18/20 | Train Loss: 1.9240, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.000500\n",
      "Epoch 19/20 | Train Loss: 1.9240, Train Acc: 0.3646 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.000500\n",
      "Epoch 20/20 | Train Loss: 1.9240, Train Acc: 0.3647 | Val Loss: 1.9253, Val Acc: 0.3640 | LR: 0.000250\n"
     ]
    }
   ],
   "source": [
    "def chad_training_validation(model, train_dataloader, validation_dataloader, criterion, optimizer, scheduler):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # enable dropout/batchnorm\n",
    "        total_train_loss = 0\n",
    "        total_train_acc = 0\n",
    "        \n",
    "        # Training\n",
    "        for data, label in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            X = data.to(device)\n",
    "            y = (label.to(device).squeeze(1) - 1).long()  # adjust if needed\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()  # update weights\n",
    "            \n",
    "            total_train_loss += loss.item() * y.size(0)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            total_train_acc += (preds == y).sum().item()\n",
    "        \n",
    "        # Update LR at end of epoch\n",
    "        scheduler.step()  \n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader.dataset)\n",
    "        avg_train_acc  = total_train_acc / len(train_dataloader.dataset)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()  # disable dropout\n",
    "        val_loss = 0\n",
    "        val_acc  = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validation_dataloader:\n",
    "                X = inputs.to(device)\n",
    "                y = (labels.to(device).squeeze(1) - 1).long()\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "                \n",
    "                val_loss += loss.item() * y.size(0)\n",
    "                _, preds = torch.max(logits, dim=1)\n",
    "                val_acc += (preds == y).sum().item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(validation_dataloader.dataset)\n",
    "        avg_val_acc  = val_acc / len(validation_dataloader.dataset)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "\n",
    "chad_training_validation(chadmodel, train_dataloader, validation_dataloader, chad_criterion, chad_optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7aba05db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.9251, Test Acc: 0.3632\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            X = inputs.to(device)\n",
    "            y = (labels.to(device).squeeze(1) - 1).long()\n",
    "            \n",
    "            logits = model(X)\n",
    "            batch_loss = criterion(logits, y)\n",
    "            \n",
    "            test_loss += batch_loss.item() * y.size(0)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            test_acc += (preds == y).sum().item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader.dataset)\n",
    "    avg_test_acc = test_acc / len(test_dataloader.dataset)\n",
    "    \n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Acc: {avg_test_acc:.4f}\")\n",
    "    \n",
    "    return avg_test_loss, avg_test_acc\n",
    "\n",
    "# Example usage after training:\n",
    "test_loss, test_acc = test_model(chadmodel, testing_dataloader, chad_criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c967f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
