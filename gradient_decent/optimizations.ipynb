{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455a489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd8ef1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./covertype-forest-cover-types\" (use force=True to force download)\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/zsinghrahulk/covertype-forest-cover-types\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ada74b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 1  Unnamed: 2  Elevation  Aspect  Slope  \\\n",
       "0        2596          51           3        258       0    510   \n",
       "1        2590          56           2        212      -6    390   \n",
       "2        2804         139           9        268      65   3180   \n",
       "3        2785         155          18        242     118   3090   \n",
       "4        2595          45           2        153      -1    391   \n",
       "\n",
       "   Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
       "0                               221                             232   \n",
       "1                               220                             235   \n",
       "2                               234                             238   \n",
       "3                               238                             238   \n",
       "4                               220                             234   \n",
       "\n",
       "   Horizontal_Distance_To_Roadways  Hillshade_9am  ...  Soil_Type32  \\\n",
       "0                              148           6279  ...            0   \n",
       "1                              151           6225  ...            0   \n",
       "2                              135           6121  ...            0   \n",
       "3                              122           6211  ...            0   \n",
       "4                              150           6172  ...            0   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0            0           5  \n",
       "1            0            0            0           5  \n",
       "2            0            0            0           2  \n",
       "3            0            0            0           2  \n",
       "4            0            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"/home/namankarki/Naman/3_months_of_data-science/Deep_Learning_Pytorch/gradient_decent/covertype-forest-cover-types/covertype.csv\"\n",
    "data_df = pd.read_csv(path)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b927674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Elevation', 'Aspect',\n",
       "       'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area', 'Soil_Type1',\n",
       "       'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6',\n",
       "       'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11',\n",
       "       'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15',\n",
       "       'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19',\n",
       "       'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23',\n",
       "       'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27',\n",
       "       'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31',\n",
       "       'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35',\n",
       "       'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39',\n",
       "       'Soil_Type40', 'Cover_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87134cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.drop(columns=(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64142013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0        258       0    510                               221   \n",
       "1        212      -6    390                               220   \n",
       "2        268      65   3180                               234   \n",
       "3        242     118   3090                               238   \n",
       "4        153      -1    391                               220   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                             232                              148   \n",
       "1                             235                              151   \n",
       "2                             238                              135   \n",
       "3                             238                              122   \n",
       "4                             234                              150   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0           6279               1              0   \n",
       "1           6225               1              0   \n",
       "2           6121               1              0   \n",
       "3           6211               1              0   \n",
       "4           6172               1              0   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                   0  ...            0            0   \n",
       "1                                   0  ...            0            0   \n",
       "2                                   0  ...            0            0   \n",
       "3                                   0  ...            0            0   \n",
       "4                                   0  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           5  \n",
       "1            0            0           5  \n",
       "2            0            0           2  \n",
       "3            0            0           2  \n",
       "4            0            0           5  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "331317fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40', 'Cover_Type']\n"
     ]
    }
   ],
   "source": [
    "columns=data_df.columns\n",
    "print(list(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee999699",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am']\n",
    "binary_cols = ['Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n",
    "label=['Cover_Type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97949951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Checking the NAN values\n",
      "Elevation                             0\n",
      "Aspect                                0\n",
      "Slope                                 0\n",
      "Horizontal_Distance_To_Hydrology      0\n",
      "Vertical_Distance_To_Hydrology        0\n",
      "Horizontal_Distance_To_Roadways       0\n",
      "Hillshade_9am                         0\n",
      "Hillshade_Noon                        0\n",
      "Hillshade_3pm                         0\n",
      "Horizontal_Distance_To_Fire_Points    0\n",
      "Wilderness_Area                       0\n",
      "Soil_Type1                            0\n",
      "Soil_Type2                            0\n",
      "Soil_Type3                            0\n",
      "Soil_Type4                            0\n",
      "Soil_Type5                            0\n",
      "Soil_Type6                            0\n",
      "Soil_Type7                            0\n",
      "Soil_Type8                            0\n",
      "Soil_Type9                            0\n",
      "Soil_Type10                           0\n",
      "Soil_Type11                           0\n",
      "Soil_Type12                           0\n",
      "Soil_Type13                           0\n",
      "Soil_Type14                           0\n",
      "Soil_Type15                           0\n",
      "Soil_Type16                           0\n",
      "Soil_Type17                           0\n",
      "Soil_Type18                           0\n",
      "Soil_Type19                           0\n",
      "Soil_Type20                           0\n",
      "Soil_Type21                           0\n",
      "Soil_Type22                           0\n",
      "Soil_Type23                           0\n",
      "Soil_Type24                           0\n",
      "Soil_Type25                           0\n",
      "Soil_Type26                           0\n",
      "Soil_Type27                           0\n",
      "Soil_Type28                           0\n",
      "Soil_Type29                           0\n",
      "Soil_Type30                           0\n",
      "Soil_Type31                           0\n",
      "Soil_Type32                           0\n",
      "Soil_Type33                           0\n",
      "Soil_Type34                           0\n",
      "Soil_Type35                           0\n",
      "Soil_Type36                           0\n",
      "Soil_Type37                           0\n",
      "Soil_Type38                           0\n",
      "Soil_Type39                           0\n",
      "Soil_Type40                           0\n",
      "Cover_Type                            0\n",
      "dtype: int64\n",
      "\n",
      " Checking the empty strings and unusual values\n",
      "Elevation                             0\n",
      "Aspect                                0\n",
      "Slope                                 0\n",
      "Horizontal_Distance_To_Hydrology      0\n",
      "Vertical_Distance_To_Hydrology        0\n",
      "Horizontal_Distance_To_Roadways       0\n",
      "Hillshade_9am                         0\n",
      "Hillshade_Noon                        0\n",
      "Hillshade_3pm                         0\n",
      "Horizontal_Distance_To_Fire_Points    0\n",
      "Wilderness_Area                       0\n",
      "Soil_Type1                            0\n",
      "Soil_Type2                            0\n",
      "Soil_Type3                            0\n",
      "Soil_Type4                            0\n",
      "Soil_Type5                            0\n",
      "Soil_Type6                            0\n",
      "Soil_Type7                            0\n",
      "Soil_Type8                            0\n",
      "Soil_Type9                            0\n",
      "Soil_Type10                           0\n",
      "Soil_Type11                           0\n",
      "Soil_Type12                           0\n",
      "Soil_Type13                           0\n",
      "Soil_Type14                           0\n",
      "Soil_Type15                           0\n",
      "Soil_Type16                           0\n",
      "Soil_Type17                           0\n",
      "Soil_Type18                           0\n",
      "Soil_Type19                           0\n",
      "Soil_Type20                           0\n",
      "Soil_Type21                           0\n",
      "Soil_Type22                           0\n",
      "Soil_Type23                           0\n",
      "Soil_Type24                           0\n",
      "Soil_Type25                           0\n",
      "Soil_Type26                           0\n",
      "Soil_Type27                           0\n",
      "Soil_Type28                           0\n",
      "Soil_Type29                           0\n",
      "Soil_Type30                           0\n",
      "Soil_Type31                           0\n",
      "Soil_Type32                           0\n",
      "Soil_Type33                           0\n",
      "Soil_Type34                           0\n",
      "Soil_Type35                           0\n",
      "Soil_Type36                           0\n",
      "Soil_Type37                           0\n",
      "Soil_Type38                           0\n",
      "Soil_Type39                           0\n",
      "Soil_Type40                           0\n",
      "Cover_Type                            0\n",
      "dtype: int64\n",
      "\n",
      " Checking the duplicates\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Checking the NAN values\")\n",
    "print(data_df.isnull().sum())\n",
    "\n",
    "print(\"\\n Checking the empty strings and unusual values\")\n",
    "print(data_df.isin([\"\", \"NA\", \"N/A\", \"NONE\", \"none\", \"na\", \"NULL\", \"null\", \"None\"]).sum())\n",
    "\n",
    "print(\"\\n Checking the duplicates\")\n",
    "print(data_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a097a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36361ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_df[numerical_cols] = scaler.fit_transform(data_df[numerical_cols])\n",
    "X = data_df.iloc[:,:-1]\n",
    "y=data_df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91478756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 52)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b5d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42e46d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e7006ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((522910, 51), (29051, 51), (29051, 51))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b9adaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,X ,y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7504084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = dataset(X_train, y_train)\n",
    "validation_dataset = dataset(X_val, y_val)\n",
    "testing_dataset = dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "684d5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_dataset, batch_size=64, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "testing_dataloader = DataLoader(testing_dataset, batch_size= 64, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d70dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2676, -0.7963, -0.5606,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3791, -0.2302,  1.1056,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.7884, -1.0364, -0.9352,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-1.1265, -0.7620,  1.0337,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0472,  2.9262,  0.4520,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        [-1.2676, -0.7963,  0.3308,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [7],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [6],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [3],\n",
      "        [7],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "for x , y in train_dataloader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86f3713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hidden_Neurons =108\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential (\n",
    "            nn.Linear(X.shape[1], Hidden_Neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(Hidden_Neurons, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU() \n",
    "        )\n",
    "        \n",
    "        self.classifier= nn.Sequential(\n",
    "            nn.Linear(16,7),\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = MyModel().to(device)\n",
    "#yo model ko output vanya batch size * 7 (7 ota calsses vako le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbeed6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 108]           5,616\n",
      "              ReLU-2                  [-1, 108]               0\n",
      "            Linear-3                   [-1, 64]           6,976\n",
      "              ReLU-4                   [-1, 64]               0\n",
      "            Linear-5                   [-1, 32]           2,080\n",
      "              ReLU-6                   [-1, 32]               0\n",
      "            Linear-7                   [-1, 16]             528\n",
      "              ReLU-8                   [-1, 16]               0\n",
      "            Linear-9                    [-1, 7]             119\n",
      "================================================================\n",
      "Total params: 15,319\n",
      "Trainable params: 15,319\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8d9c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion =nn.CrossEntropyLoss()\n",
    "optimizer =  SGD(model.parameters(), lr = 0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c167b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58959181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " Train Loss: 1.0376, Train Acc: 0.5348\n",
      " Val Loss:   0.8325, Val Acc:   0.6437\n",
      "Epoch 2/20\n",
      " Train Loss: 0.7559, Train Acc: 0.6691\n",
      " Val Loss:   0.7019, Val Acc:   0.6947\n",
      "Epoch 3/20\n",
      " Train Loss: 0.6824, Train Acc: 0.7039\n",
      " Val Loss:   0.6500, Val Acc:   0.7224\n",
      "Epoch 4/20\n",
      " Train Loss: 0.6423, Train Acc: 0.7214\n",
      " Val Loss:   0.6162, Val Acc:   0.7338\n",
      "Epoch 5/20\n",
      " Train Loss: 0.6132, Train Acc: 0.7324\n",
      " Val Loss:   0.5978, Val Acc:   0.7364\n",
      "Epoch 6/20\n",
      " Train Loss: 0.5885, Train Acc: 0.7440\n",
      " Val Loss:   0.5898, Val Acc:   0.7478\n",
      "Epoch 7/20\n",
      " Train Loss: 0.5692, Train Acc: 0.7524\n",
      " Val Loss:   0.5567, Val Acc:   0.7604\n",
      "Epoch 8/20\n",
      " Train Loss: 0.5537, Train Acc: 0.7591\n",
      " Val Loss:   0.5456, Val Acc:   0.7636\n",
      "Epoch 9/20\n",
      " Train Loss: 0.5397, Train Acc: 0.7661\n",
      " Val Loss:   0.5314, Val Acc:   0.7718\n",
      "Epoch 10/20\n",
      " Train Loss: 0.5273, Train Acc: 0.7711\n",
      " Val Loss:   0.5263, Val Acc:   0.7738\n",
      "Epoch 11/20\n",
      " Train Loss: 0.5162, Train Acc: 0.7763\n",
      " Val Loss:   0.5171, Val Acc:   0.7780\n",
      "Epoch 12/20\n",
      " Train Loss: 0.5072, Train Acc: 0.7807\n",
      " Val Loss:   0.4954, Val Acc:   0.7873\n",
      "Epoch 13/20\n",
      " Train Loss: 0.4963, Train Acc: 0.7858\n",
      " Val Loss:   0.4964, Val Acc:   0.7876\n",
      "Epoch 14/20\n",
      " Train Loss: 0.4877, Train Acc: 0.7900\n",
      " Val Loss:   0.4854, Val Acc:   0.7914\n",
      "Epoch 15/20\n",
      " Train Loss: 0.4788, Train Acc: 0.7939\n",
      " Val Loss:   0.4791, Val Acc:   0.7949\n",
      "Epoch 16/20\n",
      " Train Loss: 0.4700, Train Acc: 0.7981\n",
      " Val Loss:   0.4685, Val Acc:   0.7986\n",
      "Epoch 17/20\n",
      " Train Loss: 0.4633, Train Acc: 0.8014\n",
      " Val Loss:   0.4619, Val Acc:   0.8044\n",
      "Epoch 18/20\n",
      " Train Loss: 0.4561, Train Acc: 0.8040\n",
      " Val Loss:   0.4613, Val Acc:   0.8029\n",
      "Epoch 19/20\n",
      " Train Loss: 0.4492, Train Acc: 0.8081\n",
      " Val Loss:   0.4547, Val Acc:   0.8030\n",
      "Epoch 20/20\n",
      " Train Loss: 0.4431, Train Acc: 0.8105\n",
      " Val Loss:   0.4416, Val Acc:   0.8094\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = inputs.to(device)\n",
    "        y = (labels.to(device).squeeze(1)-1).long()\n",
    "        \n",
    "        logits = model(X)\n",
    "        batch_loss = criterion(logits, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += batch_loss.item() * y.size(0)\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        train_acc += (preds == y).sum().item()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(training_dataset)\n",
    "    avg_train_acc = train_acc / len(training_dataset)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_dataloader:\n",
    "            X = inputs.to(device)\n",
    "            y = (labels.to(device).squeeze(1)-1).long()\n",
    "            \n",
    "            logits = model(X)\n",
    "            batch_loss = criterion(logits, y)\n",
    "            \n",
    "            val_loss += batch_loss.item() * y.size(0)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            val_acc += (preds == y).sum().item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(validation_dataset)\n",
    "    avg_val_acc = val_acc / len(validation_dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\" Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}\")\n",
    "    print(f\" Val Loss:   {avg_val_loss:.4f}, Val Acc:   {avg_val_acc:.4f}\")\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2a89612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4395, Test Acc: 0.8106\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            X = inputs.to(device)\n",
    "            y = (labels.to(device).squeeze(1) - 1).long()\n",
    "            \n",
    "            logits = model(X)\n",
    "            batch_loss = criterion(logits, y)\n",
    "            \n",
    "            test_loss += batch_loss.item() * y.size(0)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            test_acc += (preds == y).sum().item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader.dataset)\n",
    "    avg_test_acc = test_acc / len(test_dataloader.dataset)\n",
    "    \n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Acc: {avg_test_acc:.4f}\")\n",
    "    \n",
    "    return avg_test_loss, avg_test_acc\n",
    "\n",
    "# Example usage after training:\n",
    "test_loss, test_acc = test_model(model, testing_dataloader, criterion, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260afaf",
   "metadata": {},
   "source": [
    "Adam Optimizer which also covers RMSPROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42c29d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hidden_Neurons = 108\n",
    "\n",
    "class MODEL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], Hidden_Neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(Hidden_Neurons, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16,7)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "mymodel = MODEL().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb3891bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 108]           5,616\n",
      "              ReLU-2                  [-1, 108]               0\n",
      "            Linear-3                   [-1, 64]           6,976\n",
      "              ReLU-4                   [-1, 64]               0\n",
      "            Linear-5                   [-1, 32]           2,080\n",
      "              ReLU-6                   [-1, 32]               0\n",
      "            Linear-7                   [-1, 16]             528\n",
      "              ReLU-8                   [-1, 16]               0\n",
      "            Linear-9                    [-1, 7]             119\n",
      "================================================================\n",
      "Total params: 15,319\n",
      "Trainable params: 15,319\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(mymodel, input_size= (X.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47311601",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(params= mymodel.parameters(), lr=0.001, betas=(0.9, 0.999), eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8ad1442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " Train Loss: 0.4851, Train Acc: 0.7850\n",
      " Val Loss:   0.4769, Val Acc:   0.7906\n",
      "Epoch 2/20\n",
      " Train Loss: 0.4655, Train Acc: 0.7940\n",
      " Val Loss:   0.4639, Val Acc:   0.7956\n",
      "Epoch 3/20\n",
      " Train Loss: 0.4493, Train Acc: 0.8017\n",
      " Val Loss:   0.4572, Val Acc:   0.7966\n",
      "Epoch 4/20\n",
      " Train Loss: 0.4361, Train Acc: 0.8080\n",
      " Val Loss:   0.4456, Val Acc:   0.8021\n",
      "Epoch 5/20\n",
      " Train Loss: 0.4242, Train Acc: 0.8146\n",
      " Val Loss:   0.4297, Val Acc:   0.8109\n",
      "Epoch 6/20\n",
      " Train Loss: 0.4138, Train Acc: 0.8195\n",
      " Val Loss:   0.4219, Val Acc:   0.8151\n",
      "Epoch 7/20\n",
      " Train Loss: 0.4049, Train Acc: 0.8235\n",
      " Val Loss:   0.4155, Val Acc:   0.8205\n",
      "Epoch 8/20\n",
      " Train Loss: 0.3979, Train Acc: 0.8270\n",
      " Val Loss:   0.4002, Val Acc:   0.8291\n",
      "Epoch 9/20\n",
      " Train Loss: 0.3914, Train Acc: 0.8302\n",
      " Val Loss:   0.3992, Val Acc:   0.8264\n",
      "Epoch 10/20\n",
      " Train Loss: 0.3852, Train Acc: 0.8329\n",
      " Val Loss:   0.3953, Val Acc:   0.8289\n",
      "Epoch 11/20\n",
      " Train Loss: 0.3796, Train Acc: 0.8358\n",
      " Val Loss:   0.3987, Val Acc:   0.8285\n",
      "Epoch 12/20\n",
      " Train Loss: 0.3756, Train Acc: 0.8379\n",
      " Val Loss:   0.3863, Val Acc:   0.8314\n",
      "Epoch 13/20\n",
      " Train Loss: 0.3715, Train Acc: 0.8400\n",
      " Val Loss:   0.3735, Val Acc:   0.8391\n",
      "Epoch 14/20\n",
      " Train Loss: 0.3676, Train Acc: 0.8415\n",
      " Val Loss:   0.3756, Val Acc:   0.8396\n",
      "Epoch 15/20\n",
      " Train Loss: 0.3627, Train Acc: 0.8439\n",
      " Val Loss:   0.3692, Val Acc:   0.8406\n",
      "Epoch 16/20\n",
      " Train Loss: 0.3596, Train Acc: 0.8458\n",
      " Val Loss:   0.3857, Val Acc:   0.8307\n",
      "Epoch 17/20\n",
      " Train Loss: 0.3557, Train Acc: 0.8477\n",
      " Val Loss:   0.3768, Val Acc:   0.8409\n",
      "Epoch 18/20\n",
      " Train Loss: 0.3527, Train Acc: 0.8493\n",
      " Val Loss:   0.3657, Val Acc:   0.8452\n",
      "Epoch 19/20\n",
      " Train Loss: 0.3505, Train Acc: 0.8502\n",
      " Val Loss:   0.3608, Val Acc:   0.8481\n",
      "Epoch 20/20\n",
      " Train Loss: 0.3480, Train Acc: 0.8514\n",
      " Val Loss:   0.3606, Val Acc:   0.8455\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "def training_validation(model,train_dataloader, validation_dataloader, criterion, optimizer):\n",
    "    for epoch in range(epochs):\n",
    "        total_train_loss = 0\n",
    "        total_train_acc = 0\n",
    "       \n",
    "        \n",
    "        for data, label in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            X = data.to(device)\n",
    "            y = (label.to(device).squeeze(1) - 1).long()\n",
    "            logits = model(X)\n",
    "            batch_loss = criterion(logits,y)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += batch_loss.item() * y.size(0)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            total_train_acc += (preds == y).sum().item()\n",
    "            \n",
    "        avg_train_loss = total_train_loss/len(training_dataset)\n",
    "        avg_train_acc = total_train_acc/len(training_dataset)\n",
    "    \n",
    "\n",
    "        # Validation\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validation_dataloader:\n",
    "                X = inputs.to(device)\n",
    "                y = (labels.to(device).squeeze(1)-1).long()\n",
    "                \n",
    "                logits = model(X)\n",
    "                batch_loss = criterion(logits, y)\n",
    "                \n",
    "                val_loss += batch_loss.item() * y.size(0)\n",
    "                _, preds = torch.max(logits, dim=1)\n",
    "                val_acc += (preds == y).sum().item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(validation_dataset)\n",
    "        avg_val_acc = val_acc / len(validation_dataset)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\" Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}\")\n",
    "        print(f\" Val Loss:   {avg_val_loss:.4f}, Val Acc:   {avg_val_acc:.4f}\")\n",
    "\n",
    "training_validation(mymodel, train_dataloader, validation_dataloader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1146c139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3559, Test Acc: 0.8475\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            X = inputs.to(device)\n",
    "            y = (labels.to(device).squeeze(1) - 1).long()\n",
    "            \n",
    "            logits = model(X)\n",
    "            batch_loss = criterion(logits, y)\n",
    "            \n",
    "            test_loss += batch_loss.item() * y.size(0)\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            test_acc += (preds == y).sum().item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader.dataset)\n",
    "    avg_test_acc = test_acc / len(test_dataloader.dataset)\n",
    "    \n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Acc: {avg_test_acc:.4f}\")\n",
    "    \n",
    "    return avg_test_loss, avg_test_acc\n",
    "\n",
    "# Example usage after training:\n",
    "test_loss, test_acc = test_model(mymodel, testing_dataloader, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c69380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
