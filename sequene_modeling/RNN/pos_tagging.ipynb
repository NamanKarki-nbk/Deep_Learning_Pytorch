{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1cbe438",
   "metadata": {},
   "source": [
    "RNN practice 1 simple exercise on POS(Parts of Speech) tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08cd2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    (\"I love NLP\", [\"PRON\", \"VERB\", \"NOUN\"]),\n",
    "    (\"Python is great\", [\"NOUN\", \"VERB\", \"ADJ\"]),\n",
    "    (\"She reads books\", [\"PRON\", \"VERB\", \"NOUN\"]),\n",
    "    (\"They play football\", [\"PRON\", \"VERB\", \"NOUN\"]),\n",
    "    (\"Machine learning is fun\", [\"NOUN\", \"NOUN\", \"VERB\", \"ADJ\"]),\n",
    "    (\"He writes code\", [\"PRON\", \"VERB\", \"NOUN\"])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11350367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I love NLP', ['PRON', 'VERB', 'NOUN']), ('Python is great', ['NOUN', 'VERB', 'ADJ']), ('She reads books', ['PRON', 'VERB', 'NOUN']), ('They play football', ['PRON', 'VERB', 'NOUN']), ('Machine learning is fun', ['NOUN', 'NOUN', 'VERB', 'ADJ']), ('He writes code', ['PRON', 'VERB', 'NOUN'])]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4978e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8561bae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'NLP', 'Python', 'is', 'great', 'She', 'reads', 'books', 'They', 'play', 'football', 'Machine', 'learning', 'is', 'fun', 'He', 'writes', 'code']\n"
     ]
    }
   ],
   "source": [
    "list_of_words = [word for sentence, tags in corpus for word in sentence.split()]\n",
    "list_of_pos = [tags for sentence, tags in corpus ]\n",
    "print(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82b14d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab=list(set(list_of_words))\n",
    "pos_vocab=list(set([pos for tags in list_of_pos for pos in tags]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0e044be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'She', 'books', 'reads', 'fun', 'He', 'NLP', 'I', 'is', 'play', 'great', 'love', 'writes', 'Machine', 'code', 'learning', 'football', 'They']\n",
      "['NOUN', 'VERB', 'ADJ', 'PRON']\n"
     ]
    }
   ],
   "source": [
    "print(input_vocab)\n",
    "print(pos_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebf00468",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\"PAD\", \"UNK\"]\n",
    "input_vocab = special_tokens + input_vocab\n",
    "pos_vocab = special_tokens + pos_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c23897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PAD': 0, 'UNK': 1, 'Python': 2, 'She': 3, 'books': 4, 'reads': 5, 'fun': 6, 'He': 7, 'NLP': 8, 'I': 9, 'is': 10, 'play': 11, 'great': 12, 'love': 13, 'writes': 14, 'Machine': 15, 'code': 16, 'learning': 17, 'football': 18, 'They': 19}\n",
      "{'PAD': 0, 'UNK': 1, 'NOUN': 2, 'VERB': 3, 'ADJ': 4, 'PRON': 5}\n"
     ]
    }
   ],
   "source": [
    "word2idx = {word: idx for idx ,word  in enumerate(input_vocab)}\n",
    "pos2idx = {pos: idx for idx, pos in enumerate(pos_vocab)}\n",
    "print(word2idx)\n",
    "print(pos2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbb9e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tags = [tag for tags in list_of_pos for tag in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e5a12ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON',\n",
       " 'VERB',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'ADJ',\n",
       " 'PRON',\n",
       " 'VERB',\n",
       " 'NOUN',\n",
       " 'PRON',\n",
       " 'VERB',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'ADJ',\n",
       " 'PRON',\n",
       " 'VERB',\n",
       " 'NOUN']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8ed9beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'love', 'NLP'], ['Python', 'is', 'great'], ['She', 'reads', 'books'], ['They', 'play', 'football'], ['Machine', 'learning', 'is', 'fun'], ['He', 'writes', 'code']]\n",
      "[['PRON', 'VERB', 'NOUN'], ['NOUN', 'VERB', 'ADJ'], ['PRON', 'VERB', 'NOUN'], ['PRON', 'VERB', 'NOUN'], ['NOUN', 'NOUN', 'VERB', 'ADJ'], ['PRON', 'VERB', 'NOUN']]\n"
     ]
    }
   ],
   "source": [
    "input_list = [item.split() for sentence, tags in corpus for item in sentence.split(\",\")]\n",
    "tag_list = [tags for sentence, tags in corpus]\n",
    "print(input_list)\n",
    "print(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3b91703",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[word2idx.get(word, word2idx[\"UNK\"]) for word in words] for words in input_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be49766f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 13, 8],\n",
       " [2, 10, 12],\n",
       " [3, 5, 4],\n",
       " [19, 11, 18],\n",
       " [15, 17, 10, 6],\n",
       " [7, 14, 16]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3856872",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[pos2idx.get(pos, pos2idx[\"UNK\"]) for pos in tags] for tags in tag_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "973cd9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 3, 2], [2, 3, 4], [5, 3, 2], [5, 3, 2], [2, 2, 3, 4], [5, 3, 2]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69ad7608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6773e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSDATASET(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.long), torch.tensor(self.Y[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b4f4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    X_padded = pad_sequence(inputs, batch_first=True, padding_value=word2idx[\"PAD\"])\n",
    "    Y_padded = pad_sequence(targets, batch_first=True, padding_value=pos2idx[\"PAD\"])\n",
    "    return X_padded, Y_padded   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c76e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = POSDATASET(x, y)  \n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aef12a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 7, 14, 16,  0],\n",
      "        [15, 17, 10,  6]]), tensor([[5, 3, 2, 0],\n",
      "        [2, 2, 3, 4]]))\n"
     ]
    }
   ],
   "source": [
    "output= next(iter(dataloader))\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8d84ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNPOSTAGGER(nn.Module):\n",
    "    def __init__(self, vocab_size,tag_size, embedding_dim=32, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2idx[\"PAD\"])\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, tag_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x) # (batch_size, seq_len, embedding_dim)\n",
    "        rnn_out, _ = self.rnn(embedded) # (batch_size, seq_len, hidden_dim)\n",
    "        logits = self.fc(rnn_out) # (batch_size, seq_len, tag_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "79c7d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNPOSTAGGER(vocab_size=len(word2idx), tag_size=len(pos2idx))\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx[\"PAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39aa3830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.2411\n",
      "Epoch 2/10, Loss: 1.1175\n",
      "Epoch 3/10, Loss: 1.2236\n",
      "Epoch 4/10, Loss: 1.1465\n",
      "Epoch 5/10, Loss: 0.8984\n",
      "Epoch 6/10, Loss: 0.8524\n",
      "Epoch 7/10, Loss: 0.8645\n",
      "Epoch 8/10, Loss: 0.6577\n",
      "Epoch 9/10, Loss: 0.6224\n",
      "Epoch 10/10, Loss: 0.5444\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for input , label in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        output = output.flatten(0,1)\n",
    "        label = label.flatten(0,1)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc419043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5760, -0.5401,  0.0755,  0.7542, -0.1608,  0.8628],\n",
      "        [-1.2989, -1.2050,  0.2034,  2.4106, -0.8838, -0.8145],\n",
      "        [-0.5971, -0.5411,  2.4322, -1.0225,  0.1000, -0.3447]])\n",
      "tensor([5, 3, 2])\n",
      "['PRON', 'VERB', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_sentence = \"He writes code\"\n",
    "    test_indices = [word2idx.get(word, word2idx[\"UNK\"]) for word in test_sentence.split()]\n",
    "    test_tensor = torch.tensor(test_indices, dtype=torch.long) \n",
    "    logits = model(test_tensor)   \n",
    "    predicted_tags = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    print(logits)\n",
    "    print(predicted_tags)\n",
    "    id2pos = {idx: pos for pos, idx in pos2idx.items()}\n",
    "    predicted_pos_tags = [id2pos[idx.item()] for idx in predicted_tags]\n",
    "    print(predicted_pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d512854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
